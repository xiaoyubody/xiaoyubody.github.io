<!DOCTYPE html>
<html>
  <!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  
  <title>爬行补天公益厂商URL - P1g3</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  
  <meta name="keywords" content="P1g3">
  
  
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.02">
  
  
    <link rel="alternate" href="/atom.xml " title="P1g3" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/style.css">
</head></html>
  <body>
    <div class="container">
      <header class="header">
  <div class="blog-title">
    <a href="/" class="logo">P1g3</a>
    <div class="subtitle"></div>
  </div>
  <nav class="navbar">
    <ul class="menu">
      
        <li class="menu-item">
          <a href="/" class="menu-item-link">Home</a>
        </li>
      
        <li class="menu-item">
          <a href="/archives" class="menu-item-link">Archives</a>
        </li>
      
        <li class="menu-item">
          <a href="/about" class="menu-item-link">About</a>
        </li>
      
        <li class="menu-item">
          <a href="/friends" class="menu-item-link">Friends</a>
        </li>
      
    </ul>
  </nav>
</header>
<article class="post">
  <div class="post-title">
    <h1 class="article-title">爬行补天公益厂商URL</h1>
  </div>
   <div class="post-meta">
    <span class="post-time">2018-11-18</span>
  </div>
  <div class="post-content">
    <p>晚上的时候有朋友和我说补天的第二季公益活动出来了，让我写个爬虫把厂商url给爬下来，于是有了这篇文章。</p>
<p>活动链接：<a href="https://butian.360.cn/Home/Active/hd.html" target="_blank" rel="noopener">https://butian.360.cn/Home/Active/hd.html</a></p>
<p>观察了一下响应之后发现，厂商的各类信息其实是从一个json里获取的。</p>
<p><img src="http://static.zybuluo.com/Em1or/ka2891q7f0n2lvyx1bde6n97/QQ%E6%88%AA%E5%9B%BE20181102133532.png" alt="QQ截图20181102133532.png-430.2kB"></p>
<p>由于信息里没有url，所以第一次尝试的时候傻傻的把标题给爬下来了…然后想用百度的搜索功能来获取url，不过这样误报太大了，后面经过提醒发现可以直接在提交漏洞处获取厂商的url。</p>
<p>于是思路就变成了：获取company_id→由company_id获取厂商url。</p>
<p>先爬一下厂商的company_id。</p>
<p><img src="http://static.zybuluo.com/Em1or/0a7uwy7bhc84z30bbmx3bi21/QQ%E6%88%AA%E5%9B%BE20181102133532.png" alt="QQ截图20181102133532.png-124.3kB"></p>
<p>我们发现是可以成功获取到的，接下来写一个保存获取到的id到文本的功能。</p>
<p><img src="http://static.zybuluo.com/Em1or/q3zxak41z08an56b0z0fmeud/QQ%E6%88%AA%E5%9B%BE20181102133532.png" alt="QQ截图20181102133532.png-160.9kB"></p>
<p>获取到id之后，接下来就是从提交漏洞里获取厂商url了。</p>
<p>这是提交漏洞的链接：<a href="https://butian.360.cn/Loo/submit?cid=" target="_blank" rel="noopener">https://butian.360.cn/Loo/submit?cid=</a></p>
<p><img src="http://static.zybuluo.com/Em1or/d9oal0y0a6y3iseffj2s7qxb/QQ%E6%88%AA%E5%9B%BE20181102133532.png" alt="QQ截图20181102133532.png-444.4kB"></p>
<p>每一个cid对应着一个厂商，提交漏洞页面处有厂商的url，我们只需要用正则把他匹配出来就好。</p>
<p>还是踩了一些坑，发现如果把获取id和获取url写到一个函数里的话，会报错，可能是因为网络问题，但是后面又试过timeout也报错，这个问题无法解决，就只能把他们写进两个函数里来分别调用了。。</p>
<p>最终成品：</p>
<p><img src="http://static.zybuluo.com/Em1or/c81w5qn8j1hticjtrn10jbu2/QQ%E6%88%AA%E5%9B%BE20181102133532.png" alt="QQ截图20181102133532.png-183.4kB"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = &apos;https://butian.360.cn/Home/Active/company&apos;</span><br><span class="line">file_handle=open(r&apos;C:\Users\Administrator\Desktop\ids.txt&apos;,mode=&apos;a+&apos;)</span><br><span class="line">urls = open(r&apos;C:\Users\Administrator\Desktop\urls.txt&apos;,mode=&apos;a+&apos;)</span><br><span class="line">headers = &#123;</span><br><span class="line"></span><br><span class="line">    &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:63.0) Gecko/20100101 Firefox/63.0&apos;,</span><br><span class="line">    &apos;Accept&apos;: &apos;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&apos;,</span><br><span class="line">    &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&apos;,</span><br><span class="line">    &apos;Accept-Encoding&apos;: &apos;gzip, deflate&apos;,</span><br><span class="line">    &apos;Referer&apos;: &apos;https://butian.360.cn/Home/Active/hd.html&apos;,</span><br><span class="line">    &apos;Connection&apos;: &apos;close&apos;,</span><br><span class="line">    &apos;Cookie&apos;: &apos;Cookie&apos;,</span><br><span class="line">    &apos;Upgrade-Insecure-Requests&apos;: &apos;1&apos;</span><br><span class="line"></span><br><span class="line">&#125;   # Cookie为你自己登陆补天时的cookie</span><br><span class="line"></span><br><span class="line">def get_id():</span><br><span class="line">    for number in range(1, 31):</span><br><span class="line">        data = &#123;&apos;type&apos;: &apos;1&apos;, &apos;p&apos;: number&#125;</span><br><span class="line">        json = requests.post(url, data=data).json()</span><br><span class="line">        company_ids = re.findall(r&apos;\&apos;company_id\&apos;: \&apos;(.*?)\&apos;&apos;, str(json))</span><br><span class="line">        for company_id in company_ids:</span><br><span class="line">            file_handle.write(company_id + &apos;\n&apos;)</span><br><span class="line">            print(company_id + &apos; is load in ids.txt&apos;)</span><br><span class="line">    print(r&apos;company_id is all load in C:\Users\Administrator\Desktop\ids.txt&apos;)</span><br><span class="line"></span><br><span class="line">def get_url():</span><br><span class="line">    ids = open(r&quot;C:\Users\Administrator\Desktop\ids.txt&quot;)</span><br><span class="line">    for id in ids:</span><br><span class="line">        id = id.strip()</span><br><span class="line">        spider = &apos;https://butian.360.cn/Loo/submit?cid=&apos;  + id</span><br><span class="line">        html = requests.get(spider, headers=headers,timeout=8).text</span><br><span class="line">        get_urls = re.findall(r&apos;&quot;请输入厂商域名&quot; value=&quot;(.*?)&quot;&apos;, html)</span><br><span class="line">        for url in get_urls:</span><br><span class="line">            if &apos;http://&apos; not in url:</span><br><span class="line">                url = &apos;http://&apos; + url</span><br><span class="line">            file_handle.write(url + &apos;\n&apos;)</span><br><span class="line">            print(url + &apos; is load in urls.txt &apos;)</span><br><span class="line">    print(r&apos;url is all load in C:\Users\Administrator\Desktop\urls.txt&apos;)</span><br><span class="line"></span><br><span class="line">get_id()</span><br><span class="line">get_url()</span><br></pre></td></tr></table></figure></p>
<p>整体来说代码还是有可以优化的地方，比如更便于和用户交互。</p>
<p>可以让用户手动输入要保存的id和url的地址。</p>
<p>这些功能优化会使代码更沉重，所以就不添加了，如果需要修改url或者id的链接，直接在file_handle和urls和ids还有后面的一些输出语句改就好了。</p>
<p>刚刚又发现了一个bug，get_id和get_url不能同时执行。</p>
<p>所以只能先get_id()一次，再get_url一次…</p>

  </div>
  <div class="post-footer">
    

    <a href="#top" class="top">Back to Top</a>
  </div>
</article>
<footer>
  &copy; 2018
  <span class="author">
    P1g3
  </span>
</footer>
    </div>
  </body>
</html>